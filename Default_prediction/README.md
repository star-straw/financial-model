**实验名称：** 基于新闻标题的企业违约分析——NLP

**实验数据来源：** 国泰安数据集 [data/all.xlsx](data/all.xlsx)

**实验背景：** 该实验旨在利用自然语言处理技术，结合GLM3和Bert_cn模型，分析中国股市上市企业的新闻标题，预测企业的违约情况。数据集涵盖了中国股市自2014年至2024年的十年间所有上市企业的新闻标题，总数超过百万条。在实验中，选择了十年间沪深A股制造业企业中的100家公司的数据作为研究对象。

**实验步骤：**

1. **数据集准备：** 
   从原始数据集中选取了十年间沪深A股制造业企业100家公司的数据作为研究对象。数据集涵盖了这些公司的新闻标题，为后续情感分析和违约预测提供了基础数据。并且删除了无意义的新闻内容，例如“xx公司xxxx年xx月xx日二级市场简报”。

2. **GLM3模型p-tuning微调：** 
   参考 [GLM3微调教程](https://blog.csdn.net/qq_40035462/article/details/135266253)，对GLM3模型进行p-tuning微调。微调过程中可能会遇到各种问题，但此处不做详细描述。

3. **利用GLM3模型进行情感分析：** 
   使用微调后的GLM3模型，对企业新闻标题进行情感分析，探索新闻标题所蕴含的情感色彩，为后续的违约预测提供情感特征。
   在实际使用GLM3的过程中，存在回复慢，忘记任务内容的情况。因此，实验中在AutoDl云端部署了RTX 4090D进行预测任务，预测数据为随机打乱的1000条数据，耗时约6小时。

4. **在Bert_cn模型上训练GLM3得到的数据集：** 
   将GLM3模型得到的数据集用于训练Bert_cn模型，以利用Bert_cn模型的强大学习能力，提高违约预测的准确性和效率。
   参考 [Bert_cn模型训练教程](https://blog.csdn.net/oXiLang/article/details/123672824)。实验中采用本地RTX 4060训练，速度较快。在实验过程中还尝试了增加LSTM和FC层以及微调超参数等方法，但效果不佳，因此保留了原文章的方法，调整了一些超参数。

5. **加载Bert检查点进行其他新闻标题的预测：** 
   利用训练好的Bert_cn模型检查点，对其他新闻标题进行违约预测，通过分析新闻标题中蕴含的信息，预测企业的违约情况。企业违约的实际指标采用企业是否存在ST。
   最终得到结果为，沪深A股的这100家制造业企业中，随着时间的推移，新闻标题对企业违约的预测准确性总体提高，最高可以接近市场总体的90%。

**备注：** 实验过程中可能涉及到数据预处理、模型调参、训练过程、结果分析等多个步骤，很多细节无法一一复述，有任何问题可以及时联系作者